{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea468eb",
   "metadata": {},
   "source": [
    "Whisper-microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9898c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: whisper-mic in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: attrs in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (22.2.0)\n",
      "Requirement already satisfied: click in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (8.1.7)\n",
      "Requirement already satisfied: ffmpeg-python in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (0.2.0)\n",
      "Requirement already satisfied: more-itertools in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (10.2.0)\n",
      "Requirement already satisfied: numpy in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (1.24.1)\n",
      "Requirement already satisfied: openai-whisper in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (20231117)\n",
      "Requirement already satisfied: pyaudio in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (0.2.13)\n",
      "Requirement already satisfied: pydantic in /Users/nori/.local/lib/python3.9/site-packages (from whisper-mic) (1.10.2)\n",
      "Requirement already satisfied: pydub in /Users/nori/.local/lib/python3.9/site-packages (from whisper-mic) (0.25.1)\n",
      "Requirement already satisfied: pynput in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (1.7.6)\n",
      "Requirement already satisfied: requests in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (2.28.1)\n",
      "Requirement already satisfied: rich in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (13.7.1)\n",
      "Requirement already satisfied: speechrecognition in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (3.10.0)\n",
      "Requirement already satisfied: tdqm in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (0.0.1)\n",
      "Requirement already satisfied: torch in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (1.13.1)\n",
      "Requirement already satisfied: transformers in /Users/nori/.local/lib/python3.9/site-packages (from whisper-mic) (4.19.2)\n",
      "Requirement already satisfied: future in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from ffmpeg-python->whisper-mic) (1.0.0)\n",
      "Requirement already satisfied: numba in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from openai-whisper->whisper-mic) (0.59.1)\n",
      "Requirement already satisfied: tqdm in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from openai-whisper->whisper-mic) (4.64.1)\n",
      "Requirement already satisfied: tiktoken in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from openai-whisper->whisper-mic) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pydantic->whisper-mic) (4.4.0)\n",
      "Requirement already satisfied: six in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pynput->whisper-mic) (1.16.0)\n",
      "Requirement already satisfied: pyobjc-framework-ApplicationServices>=8.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pynput->whisper-mic) (10.2)\n",
      "Requirement already satisfied: pyobjc-framework-Quartz>=8.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pynput->whisper-mic) (10.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from requests->whisper-mic) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from requests->whisper-mic) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from requests->whisper-mic) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from requests->whisper-mic) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from rich->whisper-mic) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from rich->whisper-mic) (2.13.0)\n",
      "Requirement already satisfied: filelock in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/nori/.local/lib/python3.9/site-packages (from transformers->whisper-mic) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (0.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nori/.local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->whisper-mic) (0.1.2)\n",
      "Requirement already satisfied: pyobjc-core>=10.2 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pyobjc-framework-ApplicationServices>=8.0->pynput->whisper-mic) (10.2)\n",
      "Requirement already satisfied: pyobjc-framework-Cocoa>=10.2 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pyobjc-framework-ApplicationServices>=8.0->pynput->whisper-mic) (10.2)\n",
      "Requirement already satisfied: pyobjc-framework-CoreText>=10.2 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pyobjc-framework-ApplicationServices>=8.0->pynput->whisper-mic) (10.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from numba->openai-whisper->whisper-mic) (0.42.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install whisper-mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8278dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import queue\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import platform\n",
    "import pynput.keyboard\n",
    "# from ctypes import *\n",
    "\n",
    "from whisper_mic.utils import get_logger\n",
    "\n",
    "#TODO: This is a linux only fix and needs to be testd.  Have one for mac and windows too.\n",
    "# Define a null error handler for libasound to silence the error message spam\n",
    "# def py_error_handler(filename, line, function, err, fmt):\n",
    "#     None\n",
    "\n",
    "# ERROR_HANDLER_FUNC = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)\n",
    "# c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)\n",
    "\n",
    "# asound = cdll.LoadLibrary('libasound.so')\n",
    "# asound.snd_lib_error_set_handler(c_error_handler)\n",
    "class WhisperMic:\n",
    "    def __init__(self,model=\"base\",device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"),english=False,verbose=False,energy=300,pause=2,dynamic_energy=False,save_file=False, model_root=\"~/.cache/whisper\",mic_index=None,implementation=\"whisper\",hallucinate_threshold=300):\n",
    "\n",
    "        self.logger = get_logger(\"whisper_mic\", \"info\")\n",
    "        self.energy = energy\n",
    "        self.hallucinate_threshold = hallucinate_threshold\n",
    "        self.pause = pause\n",
    "        self.dynamic_energy = dynamic_energy\n",
    "        self.save_file = save_file\n",
    "        self.verbose = verbose\n",
    "        self.english = english\n",
    "        self.keyboard = pynput.keyboard.Controller()\n",
    "\n",
    "        self.platform = platform.system()\n",
    "\n",
    "        if self.platform == \"darwin\":\n",
    "            if device == \"mps\":\n",
    "                self.logger.warning(\"Using MPS for Mac, this does not work but may in the future\")\n",
    "                device = \"mps\"\n",
    "                device = torch.device(device)\n",
    "\n",
    "        if (model != \"large\" and model != \"large-v2\") and self.english:\n",
    "            model = model + \".en\"\n",
    "\n",
    "        model_root = os.path.expanduser(model_root)\n",
    "\n",
    "        self.faster = False\n",
    "        if (implementation == \"faster_whisper\"):\n",
    "            try:\n",
    "                from faster_whisper import WhisperModel\n",
    "                self.audio_model = WhisperModel(model, download_root=model_root, device=\"auto\", compute_type=\"int8\")            \n",
    "                self.faster = True    # Only set the flag if we succesfully imported the library and opened the model.\n",
    "            except ImportError:\n",
    "                self.logger.error(\"faster_whisper not installed, falling back to whisper\")\n",
    "                import whisper\n",
    "                self.audio_model = whisper.load_model(model, download_root=model_root).to(device)\n",
    "\n",
    "        else:\n",
    "            import whisper\n",
    "            self.audio_model = whisper.load_model(model, download_root=model_root).to(device)\n",
    "        \n",
    "        self.temp_dir = tempfile.mkdtemp() if save_file else None\n",
    "\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.result_queue: \"queue.Queue[str]\" = queue.Queue()\n",
    "        \n",
    "        self.break_threads = False\n",
    "        self.mic_active = False\n",
    "\n",
    "        self.banned_results = [\"\",\" \",\"\\n\",None]\n",
    "\n",
    "        if save_file:\n",
    "            self.file = open(\"transcribed_text.txt\", \"w+\", encoding=\"utf-8\")\n",
    "\n",
    "        self.__setup_mic(mic_index)\n",
    "\n",
    "\n",
    "    def __setup_mic(self, mic_index):\n",
    "        if mic_index is None:\n",
    "            self.logger.info(\"No mic index provided, using default\")\n",
    "        self.source = sr.Microphone(sample_rate=16000, device_index=mic_index)\n",
    "\n",
    "        self.recorder = sr.Recognizer()\n",
    "        self.recorder.energy_threshold = self.energy\n",
    "        self.recorder.pause_threshold = self.pause\n",
    "        self.recorder.dynamic_energy_threshold = self.dynamic_energy\n",
    "\n",
    "        with self.source:\n",
    "            self.recorder.adjust_for_ambient_noise(self.source)\n",
    "\n",
    "        self.logger.info(\"Mic setup complete\")\n",
    "\n",
    "    # Whisper takes a Tensor while faster_whisper only wants an NDArray\n",
    "    def __preprocess(self, data):\n",
    "        is_audio_loud_enough = self.is_audio_loud_enough(data)\n",
    "        if self.faster:\n",
    "            return np.frombuffer(data, np.int16).flatten().astype(np.float32) / 32768.0,is_audio_loud_enough\n",
    "        else:\n",
    "            return torch.from_numpy(np.frombuffer(data, np.int16).flatten().astype(np.float32) / 32768.0),is_audio_loud_enough\n",
    "        \n",
    "    def is_audio_loud_enough(self, frame):\n",
    "        audio_frame = np.frombuffer(frame, dtype=np.int16)\n",
    "        amplitude = np.mean(np.abs(audio_frame))\n",
    "        return amplitude > self.hallucinate_threshold\n",
    "\n",
    "    \n",
    "    def __get_all_audio(self, min_time: float = -1.):\n",
    "        audio = bytes()\n",
    "        got_audio = False\n",
    "        time_start = time.time()\n",
    "        while not got_audio or time.time() - time_start < min_time:\n",
    "            while not self.audio_queue.empty():\n",
    "                audio += self.audio_queue.get()\n",
    "                got_audio = True\n",
    "\n",
    "        data = sr.AudioData(audio,16000,2)\n",
    "        data = data.get_raw_data()\n",
    "        return data\n",
    "    \n",
    "\n",
    "    # Handles the task of getting the audio input via microphone. This method has been used for listen() method\n",
    "    def __listen_handler(self, timeout, phrase_time_limit):\n",
    "        try:\n",
    "            with self.source as microphone:\n",
    "                audio = self.recorder.listen(source=microphone, timeout=timeout, phrase_time_limit=phrase_time_limit)\n",
    "            self.__record_load(0, audio)\n",
    "            audio_data = self.__get_all_audio()\n",
    "            self.__transcribe(data=audio_data)\n",
    "        except sr.WaitTimeoutError:\n",
    "            self.result_queue.put_nowait(\"Timeout: No speech detected within the specified time.\")\n",
    "        except sr.UnknownValueError:\n",
    "            self.result_queue.put_nowait(\"Speech recognition could not understand audio.\")\n",
    "\n",
    "\n",
    "    # This method is similar to the __listen_handler() method but it has the added ability for recording the audio for a specified duration of time\n",
    "    def __record_handler(self, duration, offset):\n",
    "        with self.source as microphone:\n",
    "            audio = self.recorder.record(source=microphone, duration=duration, offset=offset)\n",
    "        \n",
    "        self.__record_load(0, audio)\n",
    "        audio_data = self.__get_all_audio()\n",
    "        self.__transcribe(data=audio_data)\n",
    "\n",
    "\n",
    "    # This method takes the recorded audio data, converts it into raw format and stores it in a queue. \n",
    "    def __record_load(self,_, audio: sr.AudioData) -> None:\n",
    "        data = audio.get_raw_data()\n",
    "        self.audio_queue.put_nowait(data)\n",
    "\n",
    "\n",
    "    def __transcribe_forever(self) -> None:\n",
    "        while True:\n",
    "            if self.break_threads:\n",
    "                break\n",
    "            self.__transcribe()\n",
    "\n",
    "\n",
    "    def __transcribe(self,data=None, realtime: bool = False) -> None:\n",
    "        if data is None:\n",
    "            audio_data = self.__get_all_audio()\n",
    "        else:\n",
    "            audio_data = data\n",
    "        audio_data,is_audio_loud_enough = self.__preprocess(audio_data)\n",
    "\n",
    "        if is_audio_loud_enough:\n",
    "            predicted_text = ''\n",
    "            # faster_whisper returns an iterable object rather than a string\n",
    "            if self.faster:\n",
    "                segments, info = self.audio_model.transcribe(audio_data)\n",
    "                for segment in segments:\n",
    "                    predicted_text += segment.text\n",
    "            else:\n",
    "                if self.english:\n",
    "                    result = self.audio_model.transcribe(audio_data,language='english',suppress_tokens=\"\")\n",
    "                else:\n",
    "                    result = self.audio_model.transcribe(audio_data,suppress_tokens=\"\")\n",
    "                predicted_text = result[\"text\"]\n",
    "\n",
    "            if not self.verbose:\n",
    "                if predicted_text not in self.banned_results:\n",
    "                    self.result_queue.put_nowait(predicted_text)\n",
    "            else:\n",
    "                if predicted_text not in self.banned_results:\n",
    "                    self.result_queue.put_nowait(result)\n",
    "\n",
    "\n",
    "            if self.save_file:\n",
    "                # os.remove(audio_data)\n",
    "                self.file.write(predicted_text)\n",
    "\n",
    "    async def listen_loop_async(self, dictate: bool = False, phrase_time_limit=None) -> None:\n",
    "        for result in self.listen_continuously(phrase_time_limit=phrase_time_limit):\n",
    "            if dictate:\n",
    "                self.keyboard.type(result)\n",
    "            else:\n",
    "                yield result\n",
    "\n",
    "\n",
    "    def listen_loop(self, dictate: bool = False, phrase_time_limit=None) -> None:\n",
    "        for result in self.listen_continuously(phrase_time_limit=phrase_time_limit):\n",
    "            if dictate:\n",
    "                self.keyboard.type(result)\n",
    "            else:\n",
    "                print(result)\n",
    "\n",
    "\n",
    "    def listen_continuously(self, phrase_time_limit=None):\n",
    "        self.recorder.listen_in_background(self.source, self.__record_load, phrase_time_limit=phrase_time_limit)\n",
    "        self.logger.info(\"Listening...\")\n",
    "        threading.Thread(target=self.__transcribe_forever, daemon=True).start()\n",
    "\n",
    "        while True:\n",
    "            yield self.result_queue.get()\n",
    "\n",
    "            \n",
    "    def listen(self, timeout = None, phrase_time_limit=None):\n",
    "        self.logger.info(\"Listening...\")\n",
    "        self.__listen_handler(timeout, phrase_time_limit)\n",
    "        while True:\n",
    "            if not self.result_queue.empty():\n",
    "                return self.result_queue.get()\n",
    "\n",
    "\n",
    "    # This method is similar to the listen() method, but it has the ability to listen for a specified duration, mentioned in the \"duration\" parameter.\n",
    "    def record(self, duration=None, offset=None):\n",
    "        self.logger.info(\"Listening...\")\n",
    "        self.__record_handler(duration, offset)\n",
    "        while True:\n",
    "            if not self.result_queue.empty():\n",
    "                return self.result_queue.get()\n",
    "\n",
    "\n",
    "    def toggle_microphone(self) -> None:\n",
    "        #TO DO: make this work\n",
    "        self.mic_active = not self.mic_active\n",
    "        if self.mic_active:\n",
    "            print(\"Mic on\")\n",
    "        else:\n",
    "            print(\"turning off mic\")\n",
    "            self.mic_thread.join()\n",
    "            print(\"Mic off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa5cf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing_extensions import Literal\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "\n",
    "def get_logger(name: str, level: Literal[\"info\", \"warning\", \"debug\"]) -> logging.Logger:\n",
    "    rich_handler = RichHandler(level=logging.INFO, rich_tracebacks=True, markup=True)\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging._nameToLevel[level.upper()])\n",
    "\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(rich_handler)\n",
    "\n",
    "    logger.propagate = False\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d7ced2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwhisper_mic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from .whisper_mic import *\n",
    "from .utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2766e",
   "metadata": {},
   "source": [
    "May8th 以下は動いていない。Listenまでいくけど結果がでない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c69d35c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/08/24 09:25:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> No mic index provided, using default                                 <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#84\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">84</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/08/24 09:25:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m No mic index provided, using default                                 \u001b]8;id=879630;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=997476;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#84\u001b\\\u001b[2m84\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/08/24 09:25:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Mic setup complete                                                   <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/08/24 09:25:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Mic setup complete                                                   \u001b]8;id=358907;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=451983;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Listening<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                        <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Listening\u001b[33m...\u001b[0m                                                        \u001b]8;id=224920;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=206023;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#213\u001b\\\u001b[2m213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidCharacterException",
     "evalue": "(0, 'text')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pynput/keyboard/_base.py:491\u001b[0m, in \u001b[0;36mController.type\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease(key)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pynput/keyboard/_base.py:368\u001b[0m, in \u001b[0;36mController.press\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m\"\"\"Presses a key.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03mA key may be either a string of length 1, one of the :class:`Key`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m:raises ValueError: if ``key`` is a string, but its length is not ``1``\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m resolved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pynput/keyboard/_base.py:583\u001b[0m, in \u001b[0;36mController._resolve\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(key)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_KeyCode\u001b[38;5;241m.\u001b[39mfrom_char(key)\n",
      "\u001b[0;31mValueError\u001b[0m: text",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidCharacterException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m                 mic\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#if __name__ == \"__main__\":\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 60\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m         \u001b[43mmic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation interrupted successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py:206\u001b[0m, in \u001b[0;36mWhisperMic.listen_loop\u001b[0;34m(self, dictate, phrase_time_limit)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlisten_continuously(phrase_time_limit\u001b[38;5;241m=\u001b[39mphrase_time_limit):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dictate:\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeyboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pynput/keyboard/_base.py:495\u001b[0m, in \u001b[0;36mController.type\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease(key)\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mInvalidKeyException):\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mInvalidCharacterException(i, character)\n",
      "\u001b[0;31mInvalidCharacterException\u001b[0m: (0, 'text')"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import click\n",
    "import torch\n",
    "import speech_recognition as sr\n",
    "from typing import Optional\n",
    "\n",
    "from whisper_mic import WhisperMic\n",
    "\n",
    "'''\n",
    "@click.command()\n",
    "@click.option(\"--model\", default=\"base\", help=\"Model to use\", type=click.Choice([\"tiny\",\"base\", \"small\",\"medium\",\"large\",\"large-v2\",\"large-v3\"]))\n",
    "@click.option(\"--device\", default=(\"cuda\" if torch.cuda.is_available() else \"cpu\"), help=\"Device to use\", type=click.Choice([\"cpu\",\"cuda\",\"mps\"]))\n",
    "@click.option(\"--english\", default=False, help=\"Whether to use English model\",is_flag=True, type=bool)\n",
    "@click.option(\"--verbose\", default=False, help=\"Whether to print verbose output\", is_flag=True,type=bool)\n",
    "@click.option(\"--energy\", default=300, help=\"Energy level for mic to detect\", type=int)\n",
    "@click.option(\"--dynamic_energy\", default=False,is_flag=True, help=\"Flag to enable dynamic energy\", type=bool)\n",
    "@click.option(\"--pause\", default=0.8, help=\"Pause time before entry ends\", type=float)\n",
    "@click.option(\"--save_file\",default=False, help=\"Flag to save file\", is_flag=True,type=bool)\n",
    "@click.option(\"--loop\", default=False, help=\"Flag to loop\", is_flag=True,type=bool)\n",
    "@click.option(\"--dictate\", default=False, help=\"Flag to dictate (implies loop)\", is_flag=True,type=bool)\n",
    "@click.option(\"--mic_index\", default=None, help=\"Mic index to use\", type=int)\n",
    "@click.option(\"--list_devices\",default=False, help=\"Flag to list devices\", is_flag=True,type=bool)\n",
    "@click.option(\"--faster\",default=False, help=\"Use faster_whisper implementation\", is_flag=True,type=bool)\n",
    "@click.option(\"--hallucinate_threshold\",default=400, help=\"Raise this to reduce hallucinations.  Lower this to activate more often.\", is_flag=True,type=int)\n",
    "'''\n",
    "#def main(model: str, english: bool, verbose: bool, energy:  int, pause: float, dynamic_energy: bool, save_file: bool, device: str, loop: bool, dictate: bool,mic_index:Optional[int],list_devices: bool,faster: bool,hallucinate_threshold:int) -> None:\n",
    "def main():\n",
    "    model = \"tiny\"\n",
    "    english = False\n",
    "    verbose = True\n",
    "    energy = 200\n",
    "    pause = 0.8\n",
    "    dynamic_energy = False\n",
    "    save_file = False\n",
    "    device = \"cpu\"\n",
    "    loop = True\n",
    "    dictate = True\n",
    "    mic_index = None\n",
    "    list_devices = False\n",
    "    faster = False\n",
    "    hallucinate_threshold = 200\n",
    "\n",
    "    if list_devices:\n",
    "        print(\"Possible devices: \",sr.Microphone.list_microphone_names())\n",
    "        return\n",
    "    mic = WhisperMic(model=model, english=english, verbose=verbose, energy=energy, pause=pause, dynamic_energy=dynamic_energy, save_file=save_file, device=device,mic_index=mic_index,implementation=(\"faster_whisper\" if faster else \"whisper\"),hallucinate_threshold=hallucinate_threshold)\n",
    "\n",
    "    if not loop:\n",
    "        try:\n",
    "            result = mic.listen()\n",
    "            print(\"You said: \" + result)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Operation interrupted successfully\")\n",
    "        finally:\n",
    "            if save_file:\n",
    "                mic.file.close()\n",
    "    else:\n",
    "        try:\n",
    "            mic.listen_loop(dictate=dictate,phrase_time_limit=2)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Operation interrupted successfully\")\n",
    "        finally:\n",
    "            if save_file:\n",
    "                mic.file.close()\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df55909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper_mic import WhisperMic\n",
    "\n",
    "mic = WhisperMic(model=\"tiny\",mic_index=None,dynamic_energy=True)\n",
    "mic.listen_loop(dictate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80c3e700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/08/24 09:42:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> No mic index provided, using default                                 <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#84\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">84</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/08/24 09:42:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m No mic index provided, using default                                 \u001b]8;id=292473;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=995685;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#84\u001b\\\u001b[2m84\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/08/24 09:42:34] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Mic setup complete                                                   <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/08/24 09:42:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Mic setup complete                                                   \u001b]8;id=919133;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=644026;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Listening<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                        <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#221\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Listening\u001b[33m...\u001b[0m                                                        \u001b]8;id=753189;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=557771;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#221\u001b\\\u001b[2m221\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, can you hear me?\n"
     ]
    }
   ],
   "source": [
    "from whisper_mic import WhisperMic\n",
    "\n",
    "mic = WhisperMic()\n",
    "result = mic.listen()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74f3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
