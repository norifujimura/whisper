{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea468eb",
   "metadata": {},
   "source": [
    "Whisper-microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9898c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whisper-mic\n",
      "  Downloading whisper_mic-1.4.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (22.2.0)\n",
      "Collecting click (from whisper-mic)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting ffmpeg-python (from whisper-mic)\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: more-itertools in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (10.2.0)\n",
      "Requirement already satisfied: numpy in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (1.24.1)\n",
      "Requirement already satisfied: openai-whisper in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (20231117)\n",
      "Requirement already satisfied: pyaudio in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (0.2.13)\n",
      "Requirement already satisfied: pydantic in /Users/nori/.local/lib/python3.9/site-packages (from whisper-mic) (1.10.2)\n",
      "Requirement already satisfied: pydub in /Users/nori/.local/lib/python3.9/site-packages (from whisper-mic) (0.25.1)\n",
      "Collecting pynput (from whisper-mic)\n",
      "  Downloading pynput-1.7.6-py2.py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (2.28.1)\n",
      "Requirement already satisfied: rich in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (13.7.1)\n",
      "Requirement already satisfied: speechrecognition in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (3.10.0)\n",
      "Collecting tdqm (from whisper-mic)\n",
      "  Downloading tdqm-0.0.1.tar.gz (1.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from whisper-mic) (1.13.1)\n",
      "Requirement already satisfied: transformers in /Users/nori/.local/lib/python3.9/site-packages (from whisper-mic) (4.19.2)\n",
      "Collecting future (from ffmpeg-python->whisper-mic)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from openai-whisper->whisper-mic) (0.59.1)\n",
      "Requirement already satisfied: tqdm in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from openai-whisper->whisper-mic) (4.64.1)\n",
      "Requirement already satisfied: tiktoken in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from openai-whisper->whisper-mic) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pydantic->whisper-mic) (4.4.0)\n",
      "Requirement already satisfied: six in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from pynput->whisper-mic) (1.16.0)\n",
      "Collecting pyobjc-framework-ApplicationServices>=8.0 (from pynput->whisper-mic)\n",
      "  Downloading pyobjc_framework_ApplicationServices-10.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-Quartz>=8.0 (from pynput->whisper-mic)\n",
      "  Downloading pyobjc_framework_Quartz-10.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from requests->whisper-mic) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from requests->whisper-mic) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from requests->whisper-mic) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from requests->whisper-mic) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from rich->whisper-mic) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from rich->whisper-mic) (2.13.0)\n",
      "Requirement already satisfied: filelock in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/nori/.local/lib/python3.9/site-packages (from transformers->whisper-mic) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from transformers->whisper-mic) (0.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nori/.local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->whisper-mic) (0.1.2)\n",
      "Collecting pyobjc-core>=10.2 (from pyobjc-framework-ApplicationServices>=8.0->pynput->whisper-mic)\n",
      "  Downloading pyobjc_core-10.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-Cocoa>=10.2 (from pyobjc-framework-ApplicationServices>=8.0->pynput->whisper-mic)\n",
      "  Downloading pyobjc_framework_Cocoa-10.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CoreText>=10.2 (from pyobjc-framework-ApplicationServices>=8.0->pynput->whisper-mic)\n",
      "  Downloading pyobjc_framework_CoreText-10.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages (from numba->openai-whisper->whisper-mic) (0.42.0)\n",
      "Downloading whisper_mic-1.4.2-py3-none-any.whl (8.6 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading pynput-1.7.6-py2.py3-none-any.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyobjc_framework_ApplicationServices-10.2-cp39-cp39-macosx_10_9_universal2.whl (32 kB)\n",
      "Downloading pyobjc_framework_Quartz-10.2-cp39-cp39-macosx_10_9_universal2.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyobjc_core-10.2-cp39-cp39-macosx_10_9_universal2.whl (756 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pyobjc_framework_Cocoa-10.2-cp39-cp39-macosx_10_9_universal2.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.0/391.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyobjc_framework_CoreText-10.2-cp39-cp39-macosx_10_9_universal2.whl (31 kB)\n",
      "Building wheels for collected packages: tdqm\n",
      "  Building wheel for tdqm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1323 sha256=3bcf12e5d5e82646733371dc89ad77f065cc1a2d2f74a33d74a0cd811b17b8a9\n",
      "  Stored in directory: /Users/nori/Library/Caches/pip/wheels/cf/cf/87/969aabe5f7efa9beb7f0de846653f5cbf36bafe358451132df\n",
      "Successfully built tdqm\n",
      "Installing collected packages: tdqm, pyobjc-core, future, click, pyobjc-framework-Cocoa, ffmpeg-python, pyobjc-framework-Quartz, pyobjc-framework-CoreText, pyobjc-framework-ApplicationServices, pynput, whisper-mic\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 1.4.2 requires fsspec[http]!=2021.06.0,>=2021.05.0, which is not installed.\n",
      "pytorch-lightning 1.4.2 requires pyDeprecate==0.3.1, which is not installed.\n",
      "streamlit 1.12.0 requires blinker>=1.0.0, which is not installed.\n",
      "streamlit 1.12.0 requires pydeck>=0.1.dev5, which is not installed.\n",
      "streamlit 1.12.0 requires pympler>=0.9, which is not installed.\n",
      "streamlit 1.12.0 requires semver, which is not installed.\n",
      "streamlit 1.12.0 requires toml, which is not installed.\n",
      "streamlit 1.12.0 requires tzlocal>=1.1, which is not installed.\n",
      "streamlit 1.12.0 requires validators>=0.2, which is not installed.\n",
      "streamlit 1.12.0 requires protobuf<4,>=3.12, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed click-8.1.7 ffmpeg-python-0.2.0 future-1.0.0 pynput-1.7.6 pyobjc-core-10.2 pyobjc-framework-ApplicationServices-10.2 pyobjc-framework-Cocoa-10.2 pyobjc-framework-CoreText-10.2 pyobjc-framework-Quartz-10.2 tdqm-0.0.1 whisper-mic-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install whisper-mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8278dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import queue\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import platform\n",
    "import pynput.keyboard\n",
    "# from ctypes import *\n",
    "\n",
    "from whisper_mic.utils import get_logger\n",
    "\n",
    "#TODO: This is a linux only fix and needs to be testd.  Have one for mac and windows too.\n",
    "# Define a null error handler for libasound to silence the error message spam\n",
    "# def py_error_handler(filename, line, function, err, fmt):\n",
    "#     None\n",
    "\n",
    "# ERROR_HANDLER_FUNC = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)\n",
    "# c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)\n",
    "\n",
    "# asound = cdll.LoadLibrary('libasound.so')\n",
    "# asound.snd_lib_error_set_handler(c_error_handler)\n",
    "class WhisperMic:\n",
    "    def __init__(self,model=\"base\",device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"),english=False,verbose=False,energy=300,pause=2,dynamic_energy=False,save_file=False, model_root=\"~/.cache/whisper\",mic_index=None,implementation=\"whisper\",hallucinate_threshold=300):\n",
    "\n",
    "        self.logger = get_logger(\"whisper_mic\", \"info\")\n",
    "        self.energy = energy\n",
    "        self.hallucinate_threshold = hallucinate_threshold\n",
    "        self.pause = pause\n",
    "        self.dynamic_energy = dynamic_energy\n",
    "        self.save_file = save_file\n",
    "        self.verbose = verbose\n",
    "        self.english = english\n",
    "        self.keyboard = pynput.keyboard.Controller()\n",
    "\n",
    "        self.platform = platform.system()\n",
    "\n",
    "        if self.platform == \"darwin\":\n",
    "            if device == \"mps\":\n",
    "                self.logger.warning(\"Using MPS for Mac, this does not work but may in the future\")\n",
    "                device = \"mps\"\n",
    "                device = torch.device(device)\n",
    "\n",
    "        if (model != \"large\" and model != \"large-v2\") and self.english:\n",
    "            model = model + \".en\"\n",
    "\n",
    "        model_root = os.path.expanduser(model_root)\n",
    "\n",
    "        self.faster = False\n",
    "        if (implementation == \"faster_whisper\"):\n",
    "            try:\n",
    "                from faster_whisper import WhisperModel\n",
    "                self.audio_model = WhisperModel(model, download_root=model_root, device=\"auto\", compute_type=\"int8\")            \n",
    "                self.faster = True    # Only set the flag if we succesfully imported the library and opened the model.\n",
    "            except ImportError:\n",
    "                self.logger.error(\"faster_whisper not installed, falling back to whisper\")\n",
    "                import whisper\n",
    "                self.audio_model = whisper.load_model(model, download_root=model_root).to(device)\n",
    "\n",
    "        else:\n",
    "            import whisper\n",
    "            self.audio_model = whisper.load_model(model, download_root=model_root).to(device)\n",
    "        \n",
    "        self.temp_dir = tempfile.mkdtemp() if save_file else None\n",
    "\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.result_queue: \"queue.Queue[str]\" = queue.Queue()\n",
    "        \n",
    "        self.break_threads = False\n",
    "        self.mic_active = False\n",
    "\n",
    "        self.banned_results = [\"\",\" \",\"\\n\",None]\n",
    "\n",
    "        if save_file:\n",
    "            self.file = open(\"transcribed_text.txt\", \"w+\", encoding=\"utf-8\")\n",
    "\n",
    "        self.__setup_mic(mic_index)\n",
    "\n",
    "\n",
    "    def __setup_mic(self, mic_index):\n",
    "        if mic_index is None:\n",
    "            self.logger.info(\"No mic index provided, using default\")\n",
    "        self.source = sr.Microphone(sample_rate=16000, device_index=mic_index)\n",
    "\n",
    "        self.recorder = sr.Recognizer()\n",
    "        self.recorder.energy_threshold = self.energy\n",
    "        self.recorder.pause_threshold = self.pause\n",
    "        self.recorder.dynamic_energy_threshold = self.dynamic_energy\n",
    "\n",
    "        with self.source:\n",
    "            self.recorder.adjust_for_ambient_noise(self.source)\n",
    "\n",
    "        self.logger.info(\"Mic setup complete\")\n",
    "\n",
    "    # Whisper takes a Tensor while faster_whisper only wants an NDArray\n",
    "    def __preprocess(self, data):\n",
    "        is_audio_loud_enough = self.is_audio_loud_enough(data)\n",
    "        if self.faster:\n",
    "            return np.frombuffer(data, np.int16).flatten().astype(np.float32) / 32768.0,is_audio_loud_enough\n",
    "        else:\n",
    "            return torch.from_numpy(np.frombuffer(data, np.int16).flatten().astype(np.float32) / 32768.0),is_audio_loud_enough\n",
    "        \n",
    "    def is_audio_loud_enough(self, frame):\n",
    "        audio_frame = np.frombuffer(frame, dtype=np.int16)\n",
    "        amplitude = np.mean(np.abs(audio_frame))\n",
    "        return amplitude > self.hallucinate_threshold\n",
    "\n",
    "    \n",
    "    def __get_all_audio(self, min_time: float = -1.):\n",
    "        audio = bytes()\n",
    "        got_audio = False\n",
    "        time_start = time.time()\n",
    "        while not got_audio or time.time() - time_start < min_time:\n",
    "            while not self.audio_queue.empty():\n",
    "                audio += self.audio_queue.get()\n",
    "                got_audio = True\n",
    "\n",
    "        data = sr.AudioData(audio,16000,2)\n",
    "        data = data.get_raw_data()\n",
    "        return data\n",
    "    \n",
    "\n",
    "    # Handles the task of getting the audio input via microphone. This method has been used for listen() method\n",
    "    def __listen_handler(self, timeout, phrase_time_limit):\n",
    "        try:\n",
    "            with self.source as microphone:\n",
    "                audio = self.recorder.listen(source=microphone, timeout=timeout, phrase_time_limit=phrase_time_limit)\n",
    "            self.__record_load(0, audio)\n",
    "            audio_data = self.__get_all_audio()\n",
    "            self.__transcribe(data=audio_data)\n",
    "        except sr.WaitTimeoutError:\n",
    "            self.result_queue.put_nowait(\"Timeout: No speech detected within the specified time.\")\n",
    "        except sr.UnknownValueError:\n",
    "            self.result_queue.put_nowait(\"Speech recognition could not understand audio.\")\n",
    "\n",
    "\n",
    "    # This method is similar to the __listen_handler() method but it has the added ability for recording the audio for a specified duration of time\n",
    "    def __record_handler(self, duration, offset):\n",
    "        with self.source as microphone:\n",
    "            audio = self.recorder.record(source=microphone, duration=duration, offset=offset)\n",
    "        \n",
    "        self.__record_load(0, audio)\n",
    "        audio_data = self.__get_all_audio()\n",
    "        self.__transcribe(data=audio_data)\n",
    "\n",
    "\n",
    "    # This method takes the recorded audio data, converts it into raw format and stores it in a queue. \n",
    "    def __record_load(self,_, audio: sr.AudioData) -> None:\n",
    "        data = audio.get_raw_data()\n",
    "        self.audio_queue.put_nowait(data)\n",
    "\n",
    "\n",
    "    def __transcribe_forever(self) -> None:\n",
    "        while True:\n",
    "            if self.break_threads:\n",
    "                break\n",
    "            self.__transcribe()\n",
    "\n",
    "\n",
    "    def __transcribe(self,data=None, realtime: bool = True) -> None:\n",
    "        if data is None:\n",
    "            audio_data = self.__get_all_audio()\n",
    "        else:\n",
    "            audio_data = data\n",
    "        audio_data = self.__preprocess(audio_data)\n",
    "        #audio_data,is_audio_loud_enough = self.__preprocess(audio_data)\n",
    "\n",
    "        if is_audio_loud_enough:\n",
    "            predicted_text = ''\n",
    "            # faster_whisper returns an iterable object rather than a string\n",
    "            if self.faster:\n",
    "                segments, info = self.audio_model.transcribe(audio_data)\n",
    "                for segment in segments:\n",
    "                    predicted_text += segment.text\n",
    "            else:\n",
    "                if self.english:\n",
    "                   result = self.audio_model.transcribe(audio_data,language='english')\n",
    "                else:\n",
    "                    #result = self.audio_model.transcribe(audio_data,suppress_tokens=\"\")\n",
    "                    result = self.audio_model.transcribe(audio_data,language=\"japanese\",suppress_tokens=\"\")\n",
    "                predicted_text = result[\"text\"]\n",
    "\n",
    "            if not self.verbose:\n",
    "                if predicted_text not in self.banned_results:\n",
    "                    self.result_queue.put_nowait(predicted_text)\n",
    "            else:\n",
    "                if predicted_text not in self.banned_results:\n",
    "                    self.result_queue.put_nowait(result)\n",
    "\n",
    "\n",
    "            if self.save_file:\n",
    "                # os.remove(audio_data)\n",
    "                self.file.write(predicted_text)\n",
    "\n",
    "    async def listen_loop_async(self, dictate: bool = False, phrase_time_limit=None) -> None:\n",
    "        for result in self.listen_continuously(phrase_time_limit=phrase_time_limit):\n",
    "            if dictate:\n",
    "                self.keyboard.type(result)\n",
    "            else:\n",
    "                yield result\n",
    "\n",
    "\n",
    "    def listen_loop(self, dictate: bool = False, phrase_time_limit=None) -> None:\n",
    "        for result in self.listen_continuously(phrase_time_limit=phrase_time_limit):\n",
    "            if dictate:\n",
    "                self.keyboard.type(result)\n",
    "            else:\n",
    "                print(result)\n",
    "\n",
    "\n",
    "    def listen_continuously(self, phrase_time_limit=None):\n",
    "        self.recorder.listen_in_background(self.source, self.__record_load, phrase_time_limit=phrase_time_limit)\n",
    "        self.logger.info(\"Listening...\")\n",
    "        threading.Thread(target=self.__transcribe_forever, daemon=True).start()\n",
    "\n",
    "        while True:\n",
    "            yield self.result_queue.get()\n",
    "\n",
    "            \n",
    "    def listen(self, timeout = None, phrase_time_limit=None):\n",
    "        self.logger.info(\"Listening...\")\n",
    "        self.__listen_handler(timeout, phrase_time_limit)\n",
    "        while True:\n",
    "            if not self.result_queue.empty():\n",
    "                return self.result_queue.get()\n",
    "\n",
    "\n",
    "    # This method is similar to the listen() method, but it has the ability to listen for a specified duration, mentioned in the \"duration\" parameter.\n",
    "    def record(self, duration=None, offset=None):\n",
    "        self.logger.info(\"Listening...\")\n",
    "        self.__record_handler(duration, offset)\n",
    "        while True:\n",
    "            if not self.result_queue.empty():\n",
    "                return self.result_queue.get()\n",
    "\n",
    "\n",
    "    def toggle_microphone(self) -> None:\n",
    "        #TO DO: make this work\n",
    "        self.mic_active = not self.mic_active\n",
    "        if self.mic_active:\n",
    "            print(\"Mic on\")\n",
    "        else:\n",
    "            print(\"turning off mic\")\n",
    "            self.mic_thread.join()\n",
    "            print(\"Mic off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5cf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing_extensions import Literal\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "\n",
    "def get_logger(name: str, level: Literal[\"info\", \"warning\", \"debug\"]) -> logging.Logger:\n",
    "    rich_handler = RichHandler(level=logging.INFO, rich_tracebacks=True, markup=True)\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging._nameToLevel[level.upper()])\n",
    "\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(rich_handler)\n",
    "\n",
    "    logger.propagate = False\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d7ced2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwhisper_mic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from .whisper_mic import *\n",
    "from .utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2766e",
   "metadata": {},
   "source": [
    "May8th 以下は動いていない。Listenまでいくけど結果がでない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import click\n",
    "import torch\n",
    "import speech_recognition as sr\n",
    "from typing import Optional\n",
    "\n",
    "from whisper_mic import WhisperMic\n",
    "\n",
    "'''\n",
    "@click.command()\n",
    "@click.option(\"--model\", default=\"base\", help=\"Model to use\", type=click.Choice([\"tiny\",\"base\", \"small\",\"medium\",\"large\",\"large-v2\",\"large-v3\"]))\n",
    "@click.option(\"--device\", default=(\"cuda\" if torch.cuda.is_available() else \"cpu\"), help=\"Device to use\", type=click.Choice([\"cpu\",\"cuda\",\"mps\"]))\n",
    "@click.option(\"--english\", default=False, help=\"Whether to use English model\",is_flag=True, type=bool)\n",
    "@click.option(\"--verbose\", default=False, help=\"Whether to print verbose output\", is_flag=True,type=bool)\n",
    "@click.option(\"--energy\", default=300, help=\"Energy level for mic to detect\", type=int)\n",
    "@click.option(\"--dynamic_energy\", default=False,is_flag=True, help=\"Flag to enable dynamic energy\", type=bool)\n",
    "@click.option(\"--pause\", default=0.8, help=\"Pause time before entry ends\", type=float)\n",
    "@click.option(\"--save_file\",default=False, help=\"Flag to save file\", is_flag=True,type=bool)\n",
    "@click.option(\"--loop\", default=False, help=\"Flag to loop\", is_flag=True,type=bool)\n",
    "@click.option(\"--dictate\", default=False, help=\"Flag to dictate (implies loop)\", is_flag=True,type=bool)\n",
    "@click.option(\"--mic_index\", default=None, help=\"Mic index to use\", type=int)\n",
    "@click.option(\"--list_devices\",default=False, help=\"Flag to list devices\", is_flag=True,type=bool)\n",
    "@click.option(\"--faster\",default=False, help=\"Use faster_whisper implementation\", is_flag=True,type=bool)\n",
    "@click.option(\"--hallucinate_threshold\",default=400, help=\"Raise this to reduce hallucinations.  Lower this to activate more often.\", is_flag=True,type=int)\n",
    "'''\n",
    "#def main(model: str, english: bool, verbose: bool, energy:  int, pause: float, dynamic_energy: bool, save_file: bool, device: str, loop: bool, dictate: bool,mic_index:Optional[int],list_devices: bool,faster: bool,hallucinate_threshold:int) -> None:\n",
    "def main():\n",
    "    model = \"tiny\"\n",
    "    english = False\n",
    "    verbose = True\n",
    "    energy = 200\n",
    "    pause = 0.8\n",
    "    dynamic_energy = False\n",
    "    save_file = False\n",
    "    device = \"cpu\"\n",
    "    loop = True\n",
    "    dictate = True\n",
    "    mic_index = 2\n",
    "    list_devices = False\n",
    "    faster = False\n",
    "    hallucinate_threshold = 200\n",
    "\n",
    "    if list_devices:\n",
    "        print(\"Possible devices: \",sr.Microphone.list_microphone_names())\n",
    "        return\n",
    "    mic = WhisperMic(model=model, english=english, verbose=verbose, energy=energy, pause=pause, dynamic_energy=dynamic_energy, save_file=save_file, device=device,mic_index=mic_index,implementation=(\"faster_whisper\" if faster else \"whisper\"),hallucinate_threshold=hallucinate_threshold)\n",
    "\n",
    "    if not loop:\n",
    "        try:\n",
    "            result = mic.listen()\n",
    "            print(\"You said: \" + result)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Operation interrupted successfully\")\n",
    "        finally:\n",
    "            if save_file:\n",
    "                mic.file.close()\n",
    "    else:\n",
    "        try:\n",
    "            mic.listen_loop(dictate=dictate,phrase_time_limit=2)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Operation interrupted successfully\")\n",
    "        finally:\n",
    "            if save_file:\n",
    "                mic.file.close()\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df55909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/08/24 02:10:01] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> No mic index provided, using default                                 <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#84\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">84</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/08/24 02:10:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m No mic index provided, using default                                 \u001b]8;id=273281;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=17050;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#84\u001b\\\u001b[2m84\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/08/24 02:10:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Mic setup complete                                                   <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/08/24 02:10:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Mic setup complete                                                   \u001b]8;id=923292;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=870179;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Listening<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                        <a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">whisper_mic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Listening\u001b[33m...\u001b[0m                                                        \u001b]8;id=713934;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py\u001b\\\u001b[2mwhisper_mic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=712800;file:///Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/whisper_mic/whisper_mic.py#213\u001b\\\u001b[2m213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "江戸医中所3都賀前高第3回 Studios\n"
     ]
    }
   ],
   "source": [
    "from whisper_mic import WhisperMic\n",
    "\n",
    "mic = WhisperMic(model=\"tiny\")\n",
    "mic.listen_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3e700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
