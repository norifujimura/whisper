{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de19fae1",
   "metadata": {},
   "source": [
    "based on the code here https://qiita.com/daiarg/items/ff1b9f91d0804e6a8f18\n",
    "here's reference https://github.com/Uberi/speech_recognition/blob/master/reference/library-reference.rst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6559d",
   "metadata": {},
   "source": [
    "Google cloudに依存しているのでネットが切れると使えない。　\n",
    "Could not request results from Google Speech Recognition service; recognition connection failed: [Errno 8] nodename nor servname provided, or not known\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4e5ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something ...\n",
      "Now to recognize it...\n",
      "could not understand audio\n",
      "Say something ...\n",
      "Now to recognize it...\n",
      "国民に 鉄則を呼びかけました\n",
      "Say something ...\n",
      "Now to recognize it...\n",
      "could not understand audio\n",
      "Say something ...\n",
      "Now to recognize it...\n",
      "could not understand audio\n",
      "Say something ...\n",
      "Now to recognize it...\n",
      "2030年まで6年の人気が\n",
      "Say something ...\n",
      "Now to recognize it...\n",
      "アメリカの\n",
      "Say something ...\n",
      "Now to recognize it...\n",
      "could not understand audio\n",
      "Say something ...\n",
      "Now to recognize it...\n",
      "could not understand audio\n",
      "Say something ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mic \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[1;32m     12\u001b[0m     r\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source) \u001b[38;5;66;03m#雑音対策\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNow to recognize it...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/speech_recognition/__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    525\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/speech_recognition/__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "r.pause_threshold = 0.5\n",
    "r.energy_threshold = 200 # up to 4000\n",
    "\n",
    "while True:\n",
    "    print(\"Say something ...\")\n",
    "\n",
    "    with mic as source:\n",
    "        r.adjust_for_ambient_noise(source) #雑音対策\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    print (\"Now to recognize it...\")\n",
    "\n",
    "    try:\n",
    "        print(r.recognize_google(audio, language='ja-JP'))\n",
    "\n",
    "        # \"ストップ\" と言ったら音声認識を止める\n",
    "        if r.recognize_google(audio, language='ja-JP') == \"ストップ\" :\n",
    "            print(\"end\")\n",
    "            break\n",
    "\n",
    "    # 以下は認識できなかったときに止まらないように。\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c11201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
